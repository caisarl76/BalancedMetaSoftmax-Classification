optimizer: adam
coslr: true
criterions:
  PerformanceLoss:
    def_file: ./loss/BalancedSoftmaxLoss.py
    loss_params: {freq_path: ./cls_freq/inat.json}
    optim_params: null
    weight: 1.0
endlr: 0.0
last: false
memory: {centroids: false, init_centroids: false}
model_dir: null
networks:
  classifier:
    def_file: ./models/DotProductClassifier.py
    optim_params: {lr: 0.2, momentum: 0.9, weight_decay: 0.0005}
    params: {dataset: inat, feat_dim: 1024, log_dir: ./logs/binary/inat/models/balanced_softmax_reactnet,
      num_classes: 8142, stage1_weights: false}
  feat_model:
    def_file: ./models/reactnet.py
    fix: false
    optim_params: {lr: 0.05, momentum: 0.9, weight_decay: 0.0005}
    params: {dataset: inat, dropout: null, log_dir: ./logs/binary/inat/models/balanced_softmax_reactnet,
      stage1_weights: false, use_fc: false}
shuffle: false
training_opt:
  backbone: reactnet
  batch_size: 256
  dataset: inat
  display_step: 10
  feature_dim: 1024
  log_dir: ./logs/binary/inat/models/balanced_softmax_reactnet
  log_root: /logs/binary/inat
  num_classes: 8142
  num_epochs: 90
  num_workers: 12
  open_threshold: 0.1
  sampler: null
  scheduler_params: {gamma: 0.1, step_size: 30}
  stage: balanced_softmax_reactnet
  sub_dir: models
