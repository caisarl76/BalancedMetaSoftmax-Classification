optimizer: adam
coslr: true
criterions:
  PerformanceLoss:
    def_file: ./loss/SoftmaxLoss.py
    loss_params: {}
    optim_params: null
    weight: 1.0
endlr: 0.0
last: false
memory: {centroids: false, init_centroids: false}
model_dir: ./runs/DEFAULT/binary/softmax/adam/lr_0.01/
networks:
  classifier:
    def_file: ./models/TauNormClassifier.py
    optim_params: {lr: 0.1}
    params: {feat_dim: 1024, num_classes: 100}
  feat_model:
    def_file: ./models/reactnet.py
    fix: true
    optim_params: {lr: 0.01, betas: (0.9,0.999), eps: 1e-08}
    params: {}
shuffle: false
training_opt:
  backbone: reactnet
  batch_size: 256
  dataset: DEFAULT
  display_step: 10
  feature_dim: 1024
  log_dir: ./runs/DEFAULT/clslearn/reactnet_tau_norm
  num_classes: 100
  num_epochs: 5
  num_workers: 2
  open_threshold: 0.1
  sampler: null
  scheduler_params: {gamma: 0.1, step_size: 3}
  sub_dir: models
  imb_ratio: 0.1
