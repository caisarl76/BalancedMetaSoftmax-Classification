optimizer: sgd
coslr: true
criterions:
  PerformanceLoss:
    def_file: ./loss/BalancedSoftmaxLoss.py
    loss_params: {freq_path: ./cls_freq/CIFAR-10-LT_IMBA200.json}
    optim_params: null
    weight: 1.0
endlr: 0.0
last: false
memory: {centroids: false, init_centroids: false}
model_dir: ./logs/CIFAR10_LT/models/resnet50_softmax_imba200
networks:
  classifier:
    def_file: ./models/DotProductClassifier.py
    optim_params: {lr: 0.1, momentum: 0.9, weight_decay: 0.0005}
    params: { dataset: CIFAR10_LT, feat_dim: 2048, log_dir: ./logs/CIFAR10_LT/clslearn/balms_resnet50,
              num_classes: 10, stage1_weights: false }
  feat_model:
    def_file: ./models/ResNet50Feature.py
    fix: true
    optim_params: {lr: 0.1, momentum: 0.9, weight_decay: 0.0005}
    params: { dataset: CIFAR10_LT, dropout: null, log_dir: ./logs/CIFAR10_LT/clslearn/balms_resnet50,
              stage1_weights: false, use_fc: false, use_selfatt: false }
shuffle: false
training_opt:
  backbone: resnet50
  batch_size: 128
  dataset: CIFAR10_LT
  display_step: 10
  feature_dim: 2048
  log_dir: ./logs/CIFAR10_LT/clslearn/resnet50_balms_imba200
  num_classes: 10
  num_iterations: 2000
  num_workers: 2
  open_threshold: 0.1
  sampler: {def_file: ./data/MetaSampler.py, type: MetaSampler, meta_batch_size: 1024, init_pow: 0.1, lr: 0.001}
  scheduler_params: {gamma: 0.1, step_size: 3}
  stage: balms_resnet50
  sub_dir: clslearn
  cifar_imb_ratio: 200
